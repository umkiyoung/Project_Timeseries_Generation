model:
  target: models.diffusion.Diffusion_TS
  params:
    seq_length: 24
    n_feat: 5
    n_layer_enc: 2
    n_layer_dec: 2
    n_embd: 64  # 4 X 16
    timesteps: 500
    sampling_timesteps: 500
    loss_type: 'l1'
    n_heads: 4
    mlp_hidden_times: 4
    attn_pdrop: 0.0
    resid_pdrop: 0.0

solver:
  base_lr: 1.0e-5
  max_epochs: 10000
  results_folder: ./check_points/synthetic
  gradient_accumulate_every: 2
  save_cycle: 1000  # max_epochs // 10
  ema:
    decay: 0.995
    update_interval: 10
  
  scheduler:
    target: utils.lr_scheduler.ReduceLROnPlateauWithWarmup
    params:
      factor: 0.5
      patience: 2000
      min_lr: 1.0e-5
      threshold: 1.0e-1
      threshold_mode: rel
      warmup_lr: 8.0e-4
      warmup: 500 
      verbose: False

dataloader:
  train_dataset:
    target: data.datasets.SyntheticDataset
    params:
      n_samples: 10000
      window: 24
      feature_dim: 5
      noise_level: 2
      save_ground_truth: True
      normalize: True
      seed: 2024
      period: 'train'
      
  test_dataset:
    target: data.datasets.SyntheticDataset
    params:
      n_samples: 1000
      window: 24
      feature_dim: 5
      noise_level: 2
      save_ground_truth: True
      normalize: True
      seed: 2024
      period: 'train'
    coefficient: 1.0e-2
    step_size: 5.0e-2
    sampling_steps: 200

  batch_size: 64
  sample_size: 256
  shuffle: True